# config/llm/openai_gpt4_turbo.yaml
# GPT-4 Turbo configuration for faster responses

provider: openai
model: gpt-4-turbo
temperature: 0.0
max_tokens: 4096
timeout: 90
max_retries: 3

openai:
  api_key_env: OPENAI_API_KEY
  organization: null
  api_base: null
  api_version: null
